{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Membership Attack - solution guidelines.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "from collections import OrderedDict\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "7126f2fb-7340-4d68-fe59-cba074dbf85a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# project_path = '~/.pytorch/CIFAR10_data/'\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZthQfTYDkPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_path = '/content/drive/My Drive/cifar10/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbqRqhxLWHGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "ca33de35-4d37-44a3-8922-bd3124ba926c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "bf6c2f36-7231-4d56-d5a8-505d02918ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  car truck truck  deer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "aebbbfdf-eaab-4067-fdb3-07c8974474da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx = indices[split3:]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(8192, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "                \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E3Hj738cBPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_model = CNN()\n",
        "target_model = target_model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initalize a target model and train it\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(target_model.parameters(), lr=0.01)\n",
        "\n",
        "target_model.train()\n",
        "\n",
        "# let the magic begin\n",
        "for epoch in range(30):  \n",
        "\n",
        "    running_loss = 0\n",
        "    \n",
        "    for i, data in enumerate(target_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        # make a prediction: forward prop\n",
        "        output = target_model(inputs)\n",
        "        \n",
        "        # calculate the loss\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        # calculate gradients\n",
        "        loss.backward()\n",
        "        \n",
        "        # updaate weights in backprop\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()            \n",
        "\n",
        "    # print statistics\n",
        "    print('Epoch {} loss {}'.format(epoch, running_loss / len(iter(target_train_loader))))\n",
        "        \n",
        "        \n",
        "\n",
        "print('Finished Training the Target model...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "outputId": "242264c9-ef1d-4836-e8e2-315f9e4922b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 77 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt4L48eroR3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(target_model.state_dict(), 'target_checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKgFPagxqr3o",
        "colab_type": "code",
        "outputId": "9b8bb8c8-90e9-44d6-bb61-0e82ba19fb6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "state_dict = torch.load('/content/drive/My Drive/saved_models/target_checkpoint.pth')\n",
        "target_model.load_state_dict(state_dict)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2zfUbzx52ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shadow_model = CNN()\n",
        "shadow_model = shadow_model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "ca3bc827-9897-44b4-8190-5fd95db3dd5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_criterion = nn.CrossEntropyLoss()\n",
        "shadow_optimizer = optim.SGD(shadow_model.parameters(), lr=0.005)\n",
        "\n",
        "# let the magic begin\n",
        "for epoch in range(20):  \n",
        "\n",
        "    running_loss = 0\n",
        "    \n",
        "    for i, data in enumerate(shadow_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        shadow_optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        # make a prediction: forward prop\n",
        "        output = shadow_model(inputs)\n",
        "        \n",
        "        # calculate the loss\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        # calculate gradients\n",
        "        loss.backward()\n",
        "        \n",
        "        # updaate weights in backprop\n",
        "        shadow_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "            \n",
        "\n",
        "    # print statistics\n",
        "    print('Epoch {} loss {}'.format(epoch, running_loss / len(iter(shadow_train_loader))))\n",
        "\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 loss 0.7218988392353057\n",
            "Epoch 1 loss 0.7017893184566498\n",
            "Epoch 2 loss 0.6660919382667542\n",
            "Epoch 3 loss 0.636963704175949\n",
            "Epoch 4 loss 0.6180133372497558\n",
            "Epoch 5 loss 0.593347237815857\n",
            "Epoch 6 loss 0.5728683202552796\n",
            "Epoch 7 loss 0.5489865449619293\n",
            "Epoch 8 loss 0.539557579612732\n",
            "Epoch 9 loss 0.5229657737636566\n",
            "Epoch 10 loss 0.502370139465332\n",
            "Epoch 11 loss 0.48548810649871826\n",
            "Epoch 12 loss 0.4652671359825134\n",
            "Epoch 13 loss 0.44735063875198366\n",
            "Epoch 14 loss 0.43587500834465026\n",
            "Epoch 15 loss 0.4189693174648285\n",
            "Epoch 16 loss 0.4103548542881012\n",
            "Epoch 17 loss 0.3985494540500641\n",
            "Epoch 18 loss 0.37525907807350156\n",
            "Epoch 19 loss 0.36413238699913025\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95hpA5UeqSRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(shadow_model.state_dict(), 'shadow_checkpoint_1.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvXjQ3M-zysu",
        "colab_type": "code",
        "outputId": "828829c4-e79a-4ad7-a1d9-8c2585421560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "state_dict = torch.load('/content/drive/My Drive/saved_models/shadow_checkpoint_1.pth')\n",
        "shadow_model.load_state_dict(state_dict)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEsV3xJwppIH",
        "colab_type": "code",
        "outputId": "eca7410f-3fe3-4a08-b1d9-610fd5b2db93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 79 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# freeze the Shadow model \n",
        "shadow_model.eval()\n",
        "\n",
        "for param in shadow_model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "shadow_data = []\n",
        "\n",
        "for inputs, labels in shadow_train_loader:\n",
        "  inputs = inputs.to(device)  \n",
        "    \n",
        "#   predictions = shadow_model(inputs)\n",
        "  predictions = F.log_softmax(shadow_model(inputs), dim=1)\n",
        "   \n",
        "  for i in range(predictions.shape[0]):\n",
        "    shadow_data.append((predictions[i].sort(dim=0, descending=True)[0], 1))\n",
        "#     shadow_data.append((predictions[i], 1))\n",
        "  \n",
        "for inputs, labels in shadow_out_loader:\n",
        "  inputs = inputs.to(device)\n",
        "  \n",
        "#   predictions = shadow_model(inputs)\n",
        "  predictions = F.log_softmax(shadow_model(inputs), dim=1)\n",
        "  \n",
        "  for i in range(predictions.shape[0]):\n",
        "    shadow_data.append((predictions[i].sort(dim=0, descending=True)[0], 0))\n",
        "#     shadow_data.append((predictions[i], 0))\n",
        "\n",
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 1] and zip them together\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fl38p2AwXR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attack dataloader\n",
        "attack_train_loader = torch.utils.data.DataLoader(shadow_data, batch_size=4, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCO3G1DWZcsI",
        "colab_type": "code",
        "outputId": "156ad11e-c16a-4afe-9b8a-c186823cbbd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "attack_model = nn.Sequential(nn.Linear(10, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 2),\n",
        "                      nn.Softmax(dim=1))\n",
        "\n",
        "attack_model.to(device)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=128, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=64, out_features=2, bias=True)\n",
              "  (5): Softmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTouaLB6-z0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "8b2dff26-2fff-4c36-f7c8-a1ef83ba7157"
      },
      "source": [
        "# Make sure input looks right\n",
        "inputs, labels = iter(attack_train_loader).next()\n",
        "print(inputs[0].data.cpu().numpy())\n",
        "print(labels[0])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-3.4141541e-04 -7.9959383e+00 -1.2365501e+01 -1.5110296e+01\n",
            " -1.8584019e+01 -1.9393490e+01 -1.9635147e+01 -2.0528198e+01\n",
            " -2.1881422e+01 -2.2471889e+01]\n",
            "tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AoFVEjkDhUQ",
        "colab_type": "code",
        "outputId": "440978d1-6977-4c16-d679-29ee2badbf09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "state_dict = torch.load('/content/drive/My Drive/saved_models/attack_checkpoint.pth')\n",
        "attack_model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ymKnj7QpdDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "f8762deb-1667-44ec-e380-caa1c75e6af0"
      },
      "source": [
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "\n",
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "attack_opt = optim.Adam(attack_model.parameters(), lr=0.05)\n",
        "\n",
        "# let the magic begin\n",
        "for epoch in range(20):  \n",
        "\n",
        "    running_loss = 0\n",
        "    \n",
        "    for i, data in enumerate(attack_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "                \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        attack_opt.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        # make a prediction: forward prop\n",
        "        output = attack_model(inputs)\n",
        "                \n",
        "        # calculate the loss\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        # calculate gradients\n",
        "        loss.backward()\n",
        "        \n",
        "        # updaate weights in backprop\n",
        "        attack_opt.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "            \n",
        "\n",
        "    # print statistics\n",
        "    print('Epoch {} loss {}'.format(epoch, running_loss / len(iter(attack_train_loader))))\n",
        "    \n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 loss 0.8132616281509399\n",
            "Epoch 1 loss 0.8132616281509399\n",
            "Epoch 2 loss 0.8132616281509399\n",
            "Epoch 3 loss 0.8132616281509399\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-05c2acd7cbb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# updaate weights in backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mattack_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVPvKeEv9fby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(attack_model.state_dict(), 'attack_checkpoint_1.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1B1OhMp6er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "# and then input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "\n",
        "\n",
        "# Run attack agains the target model\n",
        "actual_value = []\n",
        "pred_value = []\n",
        "\n",
        "attack_model.eval()\n",
        "\n",
        "for param in attack_model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "for inputs, labels in target_train_loader:\n",
        "  inputs = inputs.to(device)\n",
        "  \n",
        "  # Get probability output of target model\n",
        "  output = target_model(inputs)\n",
        "  \n",
        "  # Run through attack model\n",
        "  pred = attack_model(output)\n",
        "  \n",
        "  # Pull out top class\n",
        "  top_p, top_class = pred.topk(1, dim=1)\n",
        "  \n",
        "  for i in range(top_class.shape[0]):\n",
        "    pred_value.append(top_class[0].item())\n",
        "    actual_value.append(1)\n",
        "    \n",
        "for inputs, labels in target_out_loader:\n",
        "  inputs = inputs.to(device)\n",
        "  \n",
        "  # Get probability output of target model\n",
        "  output = target_model(inputs)\n",
        "  \n",
        "  # Run through attack model\n",
        "  pred = attack_model(output)\n",
        "  \n",
        "  # Pull out top class\n",
        "  top_p, top_class = pred.topk(1, dim=1)\n",
        "  \n",
        "  for i in range(top_class.shape[0]):\n",
        "    pred_value.append(top_class[0].item())\n",
        "    actual_value.append(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BsW9xY66x8I",
        "colab_type": "code",
        "outputId": "6678163f-b998-462b-9463-47bd9252f54d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Calculate recall and precision\n",
        "# precison = true positive / true positive + false positive\n",
        "true_pos = 0\n",
        "false_neg = 0\n",
        "\n",
        "total_positive = sum(pred_value)\n",
        "for i in range(len(actual_value)):\n",
        "  if (pred_value[i] == 1) and (actual_value[i] == 1):\n",
        "    true_pos += 1\n",
        "  elif (pred_value[i] == 0) and (actual_value[i] == 1):\n",
        "    false_neg += 1\n",
        "    \n",
        "print('True positive: {} Total Positive: {} Precision: {}'.format(true_pos, total_positive, true_pos / total_positive))\n",
        "print('Recall: {}'.format(true_pos / (true_pos + false_neg)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True positive: 7120 Total Positive: 14196 Precision: 0.501549732318963\n",
            "Recall: 0.5696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Great! At this point, you must have created a succesfful attack model that can detect whether a datapoint was used in training a target mode or not. \n",
        "* A successful attack model is one with a precision/recall higher than 85% -- you are using same architecture and are aware of the data classes\n",
        "\n",
        " \n",
        " Can you suggest any defense mechanism? If yes, Apply them to your solution and re-evaluate your attack model. How did your defense mecanism affect the accuracy of the target model? How did it affect the recall and precision of the Attack model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlYh8eUAOanS",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 1\n",
        "Carry out membership inference attack on a model whose architecture is unknown. The target model will be the same CNN from the ICP. The shadow model will be resnet18 with a Fully Connected head for CIFAR-10 classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otOpNRUzp_eC",
        "colab_type": "text"
      },
      "source": [
        "#Shadow Model Definition and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc7qdmQBB_lt",
        "colab_type": "code",
        "outputId": "36ccdd22-fb0e-458b-d295-69e193532a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# pull down pretrained model\n",
        "shadow_model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze convolutional layers\n",
        "for param in shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "shadow_model.fc = nn.Linear(512, 10)\n",
        "\n",
        "shadow_model = shadow_model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 46827520/46827520 [00:00<00:00, 110983261.97it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stHXwRJTQLhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images\n",
        "cifar10_mean = [0.4915, 0.4823, 0.4468]\n",
        "cifar10_std  = [0.2470, 0.2435, 0.2616]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar10_mean, cifar10_std)\n",
        "])\n",
        "\n",
        "transform_test = transform\n",
        "transform_train = transform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGsYZBvHQZWt",
        "colab_type": "code",
        "outputId": "5f51cd40-1a13-417c-ff18-ec9cb29bdb60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "shadow_train_set = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(shadow_train_set, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(shadow_train_set, batch_size=batch_size, sampler=shadow_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaJSp6GUp85v",
        "colab_type": "code",
        "outputId": "2d558c5f-a0cd-40ea-e8a3-4e94206a33fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "# Train model\n",
        "optimizer = optim.SGD(shadow_model.fc.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    running_loss = 0\n",
        "    \n",
        "    for i, data in enumerate(shadow_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        # make a prediction: forward prop\n",
        "        output = shadow_model(inputs)\n",
        "        \n",
        "        # calculate the loss\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        # calculate gradients\n",
        "        loss.backward()\n",
        "        \n",
        "        # updaate weights in backprop\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()            \n",
        "\n",
        "    # print statistics\n",
        "    print('Epoch {} loss {}'.format(epoch, running_loss / len(iter(shadow_train_loader))))\n",
        "\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 loss 1.851427352794296\n",
            "Epoch 1 loss 1.3047815850171287\n",
            "Epoch 2 loss 1.10060143653694\n",
            "Epoch 3 loss 0.9908403562157965\n",
            "Epoch 4 loss 0.9274591654158004\n",
            "Epoch 5 loss 0.8791889847849336\n",
            "Epoch 6 loss 0.8438573120652563\n",
            "Epoch 7 loss 0.821930570294485\n",
            "Epoch 8 loss 0.7992521979848443\n",
            "Epoch 9 loss 0.7857093333512011\n",
            "Epoch 10 loss 0.7703799887005326\n",
            "Epoch 11 loss 0.7577778272464147\n",
            "Epoch 12 loss 0.7458517409079825\n",
            "Epoch 13 loss 0.7357047093112755\n",
            "Epoch 14 loss 0.7273708373460623\n",
            "Epoch 15 loss 0.7260105275665708\n",
            "Epoch 16 loss 0.7082978080758049\n",
            "Epoch 17 loss 0.7049631125786725\n",
            "Epoch 18 loss 0.7041282978318536\n",
            "Epoch 19 loss 0.6975781544090232\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng1Ab25IuMsK",
        "colab_type": "code",
        "outputId": "2ab222a4-51c3-44b3-b374-eed170a8d44f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in shadow_out_loader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 74 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4_-d6n1Jo-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(shadow_model.state_dict(), 'shadow_checkpoint_2.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rwhEopuR1zG",
        "colab_type": "code",
        "outputId": "40130223-e16c-439f-c94e-abfc4773bd23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "state_dict = torch.load('/content/drive/My Drive/saved_models/shadow_checkpoint_2.pth')\n",
        "shadow_model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeIibNo0Hg5S",
        "colab_type": "text"
      },
      "source": [
        "#Define and Train Attack Model\n",
        "\n",
        "\n",
        "1.   Generate attack model training data\n",
        "2.   Define attack model\n",
        "3.   Train model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgId9ZAnEBio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create helper to generate attack data\n",
        "def generate_attack_data(shadow_model, in_data, out_data):\n",
        "  # freeze the Shadow model \n",
        "  shadow_model.eval()\n",
        "\n",
        "  for param in shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "  # make predictions on both datasets (shadow_in and shdow_out)\n",
        "  attack_data = []\n",
        "\n",
        "  for inputs, labels in in_data:\n",
        "    inputs = inputs.to(device)  \n",
        "\n",
        "    predictions = shadow_model(inputs)\n",
        "  #   predictions = F.softmax(shadow_model(inputs), dim=1)\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "      attack_data.append((predictions[i], 1))\n",
        "\n",
        "  for inputs, labels in out_data:\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    predictions = shadow_model(inputs)\n",
        "  #   predictions = F.softmax(shadow_model(inputs), dim=1)\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "      attack_data.append((predictions[i], 0))\n",
        "      \n",
        "  return attack_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y72kHjkNGD5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up attack train data\n",
        "attack_data = generate_attack_data(shadow_model, shadow_train_loader, shadow_out_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mI4i9W_LfdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attack_train_loader = torch.utils.data.DataLoader(attack_data, batch_size=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPP7eJEVGV-w",
        "colab_type": "code",
        "outputId": "db4b3bcb-1f5d-4934-ac01-90e721264aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# Define attack model\n",
        "attack_model = nn.Sequential(nn.Linear(10, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 2))\n",
        "\n",
        "attack_model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=128, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0vi85MuH77s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model\n",
        "optimizer = optim.SGD(attack_model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    running_loss = 0\n",
        "    \n",
        "    for i, data in enumerate(attack_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        # make a prediction: forward prop\n",
        "        output = attack_model(inputs)\n",
        "        \n",
        "        # calculate the loss\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        # calculate gradients\n",
        "        loss.backward()\n",
        "        \n",
        "        # updaate weights in backprop\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()            \n",
        "\n",
        "    # print statistics\n",
        "    print('Epoch {} loss {}'.format(epoch, running_loss / len(iter(attack_train_loader))))\n",
        "\n",
        "print('Finished Training the Attack model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1yiNDjdLxkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(attack_model.state_dict(), 'attack_checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Qf7GBlR6Yh",
        "colab_type": "code",
        "outputId": "162ae0ad-df10-4329-ee6e-5aa7976a64a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "state_dict = torch.load('attack_checkpoint.pth')\n",
        "attack_model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2ryP0QcItqg",
        "colab_type": "text"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyibwGLiIxAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "# and then input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "\n",
        "\n",
        "# Run attack agains the target model\n",
        "actual_value = []\n",
        "pred_value = []\n",
        "\n",
        "attack_model.eval()\n",
        "\n",
        "for param in attack_model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "for inputs, labels in target_train_loader:\n",
        "  inputs = inputs.to(device)\n",
        "  \n",
        "  # Get probability output of target model\n",
        "  output = target_model(inputs)\n",
        "  \n",
        "  # Run through attack model\n",
        "  pred = attack_model(output)\n",
        "  \n",
        "  # Pull out top class\n",
        "  top_p, top_class = pred.topk(1, dim=1)\n",
        "  \n",
        "  for i in range(top_class.shape[0]):\n",
        "    pred_value.append(top_class[0].item())\n",
        "    actual_value.append(1)\n",
        "    \n",
        "for inputs, labels in target_out_loader:\n",
        "  inputs = inputs.to(device)\n",
        "  \n",
        "  # Get probability output of target model\n",
        "  output = target_model(inputs)\n",
        "  \n",
        "  # Run through attack model\n",
        "  pred = attack_model(output)\n",
        "  \n",
        "  # Pull out top class\n",
        "  top_p, top_class = pred.topk(1, dim=1)\n",
        "  \n",
        "  for i in range(top_class.shape[0]):\n",
        "    pred_value.append(top_class[0].item())\n",
        "    actual_value.append(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1Gv9DGLJA6T",
        "colab_type": "code",
        "outputId": "40fc889a-f240-4925-f6c9-7e7f4600c590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Calculate recall and precision\n",
        "# precison = true positive / true positive + false positive\n",
        "true_pos = 0\n",
        "false_neg = 0\n",
        "\n",
        "total_positive = sum(pred_value)\n",
        "for i in range(len(actual_value)):\n",
        "  if (pred_value[i] == 1) and (actual_value[i] == 1):\n",
        "    true_pos += 1\n",
        "  elif (pred_value[i] == 0 and actual_value[i] == 1):\n",
        "    false_neg += 1\n",
        "    \n",
        "print('True positive: {} Total Positive: {} Precision: {}'.format(true_pos, total_positive, true_pos / total_positive))\n",
        "print('Recall: {}'.format(true_pos / (true_pos + false_neg)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True positive: 3504 Total Positive: 7456 Precision: 0.4699570815450644\n",
            "Recall: 0.28032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCFohe9pSjt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}